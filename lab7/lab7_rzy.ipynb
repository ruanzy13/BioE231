{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for lab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "#Generate 100 megabytes of random data containing 100%, 90%, 80%, 70%, 60%, and 50% zeros.\n",
    "myzeros_100p = np.random.choice([0,1], size=800000000,replace=True,p=[1,0])\n",
    "myzeros_100p = np.packbits(myzeros_100p)\n",
    "open(\"zeros_100P\",\"wb\").write(myzeros_100p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing the zeros_100p as an example, copy the readout from the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of input file: 100MB\n",
    "time gzip -k zeros_100P\n",
    "real    0m0.693s\n",
    "user    0m0.665s\n",
    "sys     0m0.028s\n",
    "size of output file: 97.1kB\n",
    "\n",
    "time bzip2 -k zeros_100P\n",
    "real    0m1.004s\n",
    "user    0m0.912s\n",
    "sys     0m0.092s\n",
    "size of output file: 113B\n",
    "\n",
    "time pbzip2 -k zeros_100P\n",
    "real    0m0.102s\n",
    "user    0m1.873s\n",
    "sys     0m0.099s\n",
    "size of output file: 5.38kB\n",
    "\n",
    "time ArithmeticCompress zeros_100P zeros_100P.art\n",
    "real    0m14.292s\n",
    "user    0m14.079s\n",
    "sys     0m0.212s\n",
    "size of output file: 1.03kB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use subprocess module to visualize readout from terminal at ipython notebook, below is an example of run command \"time ArithmeticCompress zeros_100p zeros_100p.art\", from where we can see 41.04 represents user time, 0.23 represents sys time, and 0:41.41s represents the real compressing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'41.03user 0.23system 0:41.41elapsed 99%CPU (0avgtext+0avgdata 4288maxresident)k\\n1488inputs+195320outputs (4major+233minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "import subprocess,sys\n",
    "command =['time','ArithmeticCompress', 'zeros_100p','zeros_100p.art']\n",
    "p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "(stdoutdata, stderrdata)=p.communicate()\n",
    "print(stderrdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I will generate 100 megabytes of random data containing 90%, 80%, 70%, 60%, and 50% zeros, and compress them by gzip, bzip2, pbzip2, ArithmeticCompress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Zero_pos=[90,80,70,60,50]\n",
    "for pos in Zero_pos:\n",
    "    filename=\"zeros_\"+str(pos)+\"P\"\n",
    "    myvar= np.random.choice([0,1], size=800000000,replace=True,p=[pos/100,1-pos/100])\n",
    "    myvar = np.packbits(myvar)\n",
    "    open(filename,\"wb\").write(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zeros_90P', 'zeros_80P', 'zeros_70P', 'zeros_60P', 'zeros_50P']\n",
      "zeros_90P b'17.81user 0.14system 0:17.96elapsed 99%CPU (0avgtext+0avgdata 1820maxresident)k\\n0inputs+109408outputs (0major+137minor)pagefaults 0swaps\\n'\n",
      "zeros_80P b'12.76user 0.12system 0:12.89elapsed 99%CPU (0avgtext+0avgdata 1860maxresident)k\\n0inputs+151176outputs (0major+132minor)pagefaults 0swaps\\n'\n",
      "zeros_70P b'5.74user 0.09system 0:05.83elapsed 100%CPU (0avgtext+0avgdata 1776maxresident)k\\n0inputs+174376outputs (0major+130minor)pagefaults 0swaps\\n'\n",
      "zeros_60P b'4.66user 0.18system 0:04.85elapsed 99%CPU (0avgtext+0avgdata 1784maxresident)k\\n0inputs+190776outputs (0major+131minor)pagefaults 0swaps\\n'\n",
      "zeros_50P b'3.24user 0.12system 0:03.37elapsed 99%CPU (0avgtext+0avgdata 1808maxresident)k\\n0inputs+195344outputs (0major+131minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "import subprocess,sys\n",
    "files=[]\n",
    "for pos in Zero_pos:\n",
    "    name = \"zeros_\"+str(pos)+\"P\"\n",
    "    files.append(name)\n",
    "print(files)\n",
    "#run gzip for each file\n",
    "for file in files:\n",
    "    command =['time','gzip', '-k',file]\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(file,stderrdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros_90P b'18.28user 0.77system 0:00.76elapsed 2477%CPU (0avgtext+0avgdata 270324maxresident)k\\n0inputs+113968outputs (0major+214137minor)pagefaults 0swaps\\n'\n",
      "zeros_80P b'22.33user 0.85system 0:00.92elapsed 2515%CPU (0avgtext+0avgdata 278552maxresident)k\\n0inputs+161424outputs (0major+219271minor)pagefaults 0swaps\\n'\n",
      "zeros_70P b'28.04user 0.73system 0:01.09elapsed 2618%CPU (0avgtext+0avgdata 280448maxresident)k\\n0inputs+185832outputs (0major+225112minor)pagefaults 0swaps\\n'\n",
      "zeros_60P b'34.16user 0.75system 0:01.26elapsed 2758%CPU (0avgtext+0avgdata 283524maxresident)k\\n0inputs+195432outputs (0major+247616minor)pagefaults 0swaps\\n'\n",
      "zeros_50P b'38.03user 0.84system 0:01.39elapsed 2789%CPU (0avgtext+0avgdata 285344maxresident)k\\n0inputs+196184outputs (0major+260505minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "# run pbzip2 for each file\n",
    "for file in files:\n",
    "    command =['time','pbzip2', '-k',file]\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(file,stderrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros_90P b'27.29user 0.16system 0:27.45elapsed 99%CPU (0avgtext+0avgdata 4324maxresident)k\\n0inputs+91608outputs (0major+238minor)pagefaults 0swaps\\n'\n",
      "zeros_80P b'33.60user 0.23system 0:33.84elapsed 99%CPU (0avgtext+0avgdata 4224maxresident)k\\n0inputs+141008outputs (0major+234minor)pagefaults 0swaps\\n'\n",
      "zeros_70P b'38.10user 0.25system 0:38.36elapsed 100%CPU (0avgtext+0avgdata 4308maxresident)k\\n0inputs+172128outputs (0major+232minor)pagefaults 0swaps\\n'\n",
      "zeros_60P b'38.78user 0.26system 0:39.13elapsed 99%CPU (0avgtext+0avgdata 4296maxresident)k\\n0inputs+189648outputs (0major+233minor)pagefaults 0swaps\\n'\n",
      "zeros_50P b'38.58user 0.30system 0:38.88elapsed 99%CPU (0avgtext+0avgdata 4232maxresident)k\\n0inputs+195320outputs (0major+234minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "# run ArithmeticCompress for each file\n",
    "for file in files:\n",
    "    command =['time','ArithmeticCompress', file, file+\".art\"]\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(file,stderrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros_90P b'10.07user 0.06system 0:10.14elapsed 99%CPU (0avgtext+0avgdata 7748maxresident)k\\n72inputs+113920outputs (1major+1689minor)pagefaults 0swaps\\n'\n",
      "zeros_80P b'11.88user 0.11system 0:12.00elapsed 99%CPU (0avgtext+0avgdata 7736maxresident)k\\n0inputs+161392outputs (0major+1690minor)pagefaults 0swaps\\n'\n",
      "zeros_70P b'13.12user 0.11system 0:13.24elapsed 99%CPU (0avgtext+0avgdata 7720maxresident)k\\n0inputs+185824outputs (0major+1691minor)pagefaults 0swaps\\n'\n",
      "zeros_60P b'14.76user 0.10system 0:14.87elapsed 99%CPU (0avgtext+0avgdata 7820maxresident)k\\n0inputs+195416outputs (0major+1691minor)pagefaults 0swaps\\n'\n",
      "zeros_50P b'15.76user 0.08system 0:15.85elapsed 99%CPU (0avgtext+0avgdata 7824maxresident)k\\n0inputs+196176outputs (0major+1691minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "# run bzip2 for each file\n",
    "for file in files:\n",
    "    command =['time','bzip2', '-k',file]\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(file,stderrdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 100 million long DNA/ Protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydna=np.random.choice(['A','T','C','G'],size = 100000000,replace=True,p=[0.25,0.25,0.25,0.25])\n",
    "dna_seq=\"\".join(mydna)\n",
    "open(\"nt_seq\",\"w\").write(dna_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypro=np.random.choice(['A','G','I','L','P','V','F','W','Y','D','E','R','H','K','S','T','C','M','N','Q'],\\\n",
    "                       size = 100000000,replace=True,p=[0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05])\n",
    "pro_seq=\"\".join(mypro)\n",
    "open(\"pro_seq\",\"w\").write(pro_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress protein/dna file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt_seq gzip b'12.08user 0.06system 0:12.15elapsed 100%CPU (0avgtext+0avgdata 1852maxresident)k\\n0inputs+57080outputs (0major+142minor)pagefaults 0swaps\\n'\n",
      "pro_seq gzip b'4.14user 0.05system 0:04.20elapsed 99%CPU (0avgtext+0avgdata 1836maxresident)k\\n0inputs+118280outputs (0major+137minor)pagefaults 0swaps\\n'\n",
      "nt_seq bzip2 b'9.39user 0.03system 0:09.43elapsed 99%CPU (0avgtext+0avgdata 7728maxresident)k\\n0inputs+53392outputs (0major+1690minor)pagefaults 0swaps\\n'\n",
      "pro_seq bzip2 b'9.87user 0.06system 0:09.94elapsed 99%CPU (0avgtext+0avgdata 7700maxresident)k\\n0inputs+107912outputs (0major+1689minor)pagefaults 0swaps\\n'\n",
      "nt_seq.art ArithmeticCompress b'21.25user 0.06system 0:21.31elapsed 99%CPU (0avgtext+0avgdata 4296maxresident)k\\n0inputs+48832outputs (0major+234minor)pagefaults 0swaps\\n'\n",
      "pro_seq.art ArithmeticCompress b'29.38user 0.17system 0:29.55elapsed 99%CPU (0avgtext+0avgdata 4292maxresident)k\\n0inputs+105520outputs (0major+235minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "commands =[['time','gzip', '-k','nt_seq'],\\\n",
    "           ['time','gzip', '-k','pro_seq'],\\\n",
    "           ['time','bzip2', '-k','nt_seq'],\\\n",
    "           ['time','bzip2', '-k','pro_seq'],\\\n",
    "           ['time','ArithmeticCompress', 'nt_seq', 'nt_seq.art'],\\\n",
    "           ['time','ArithmeticCompress', 'pro_seq', 'pro_seq.art']]\n",
    "for command in commands:\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(command[3],command[1],stderrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt_seq pbzip2 b'16.24user 0.82system 0:00.66elapsed 2565%CPU (0avgtext+0avgdata 265728maxresident)k\\n0inputs+53400outputs (0major+207269minor)pagefaults 0swaps\\n'\n",
      "pro_seq pbzip2 b'18.95user 0.68system 0:00.78elapsed 2507%CPU (0avgtext+0avgdata 269248maxresident)k\\n0inputs+107936outputs (0major+213386minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "commands =[['time','pbzip2', '-k','nt_seq'],['time','pbzip2', '-k','pro_seq']]\n",
    "for command in commands:\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(command[3],command[1],stderrdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table to keep track of the size of input files, the size of the output files, and the time each command took to run  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zeros_100p', 'gzip', '100MB', '97.1kB', '0.693s'), ('zeros_100p', 'bzip2', '100MB', '113B', '1.004s'), ('zeros_100p', 'pbzip2', '100MB', '5.38kB', '0.102s'), ('zeros_100p', 'ArithmeticCompress', '100MB', '1.03kB', '14.292s')]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "algorithm_array=[('zeros_100p','gzip','100MB','97.1kB','0.693s'),\n",
    "                 ('zeros_100p','bzip2','100MB','113B','1.004s'),\n",
    "                 ('zeros_100p','pbzip2','100MB','5.38kB','0.102s'),\n",
    "                 ('zeros_100p','ArithmeticCompress','100MB','1.03kB','14.292s'),\n",
    "                 ('zeros_90p','gzip','100MB','56MB','17.96s'),\n",
    "                 ('zeros_90p','bzip2','100MB','58.3MB','10.14s'),\n",
    "                 ('zeros_90p','pbzip2','100MB','58.3MB','0.76s'),\n",
    "                 ('zeros_90p','ArithmeticCompress','100MB','46.9MB','27.45s'),\n",
    "                 ('zeros_80p','gzip','100MB','77.4MB','12.89s'),\n",
    "                 ('zeros_80p','bzip2','100MB','82.6MB','12.00s'),\n",
    "                 ('zeros_80p','pbzip2','100MB','82.6MB','0.92s'),\n",
    "                 ('zeros_80p','ArithmeticCompress','100MB','72.2MB','33.84s'),\n",
    "                 ('zeros_70p','gzip','100MB','89.3MB','5.83s'),\n",
    "                 ('zeros_70p','bzip2','100MB','95.1MB','13.24s'),\n",
    "                 ('zeros_70p','pbzip2','100MB','95.1MB','1.09s'),\n",
    "                 ('zeros_70p','ArithmeticCompress','100MB','88.1MB','38.36s'),\n",
    "                 ('zeros_60p','gzip','100MB','97.7MB','4.85s'),\n",
    "                 ('zeros_60p','bzip2','100MB','100MB','14.87s'),\n",
    "                 ('zeros_60p','pbzip2','100MB','100MB','1.26s'),\n",
    "                 ('zeros_60p','ArithmeticCompress','100MB','97.1MB','39.13s'),\n",
    "                 ('zeros_50p','gzip','100MB','100MB','3.37s'),\n",
    "                 ('zeros_50p','bzip2','100MB','100MB','15.85s'),\n",
    "                 ('zeros_50p','pbzip2','100MB','100MB','1.39s'),\n",
    "                 ('zeros_50p','ArithmeticCompress','100MB','100MB','38.88s'),\n",
    "                 ('nt_seq','gzip','100MB','29.2MB','12.15s'),\n",
    "                 ('pro_seq','gzip','100MB','60.6MB','4.20s'),\n",
    "                 ('nt_seq','bzip','100MB','27.3MB','9.43s'),\n",
    "                 ('pro_seq','bzip','100MB','55.3MB','9.94s'),\n",
    "                 ('nt_seq','pbzip','100MB','27.3MB','0.66s'),\n",
    "                 ('pro_seq','pbzip','100MB','55.3MB','0.78s'),\n",
    "                 ('nt_seq','ArithmeticCompress','100MB','25MB','21.31s'),\n",
    "                 ('pro_seq','ArithmeticCompress','100MB','54MB','29.55s')\n",
    "                ]\n",
    "# connect database\n",
    "conn = sqlite3.connect('compression.db')\n",
    "c = conn.cursor()\n",
    "# create tables: compress\n",
    "c.execute(\"\"\"CREATE TABLE compress (name TEXT,algorithm TEXT,size_input TEXT,size_output TEXT,realtime TEXT)\"\"\")\n",
    "c.executemany('INSERT INTO compress VALUES (?,?,?,?,?)',algorithm_array)\n",
    "conn.commit()\n",
    "t = ('zeros_100p',)\n",
    "c.execute('SELECT * FROM compress WHERE name=?', t)\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Observation in random zeros file_**\n",
    "1. Generally, ArithmeticCompress achieves the best level of compression on each file type. \n",
    "2. pbzip2 is the fastest algorithm.\n",
    "3. pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear seedup on SMP machines. According to that, generally speaking, pbzip2 find a way that can save running time of compression without comprimising quality of compression.pbzip2 is faster than bzip2.\n",
    "4. As the percentage of zeros increases, the space to keep the compression file decrease. According to Shannon entroy, higher probability of zeros, lower entropy zeros would have, and therefore, less space is needed for such less information.\n",
    "5. Q: what is the minimum number of bits required to store a single DNA base?\n",
    "   A:8 bits\n",
    "6. Q: What is the minimum number of bits required to store an amino acid letter?\n",
    "   A: 8 bits\n",
    "7. In gzip, 29.2*1024*1024*8 bits for DNA, 60.6*1024*1024*8 bits for amino acids\n",
    "   In bzip2, 27.3*1024*1024*8 bits for DNA, 55.3*1024*1024*8 bits for amino acids\n",
    "8. bzip perform better than gzip for DNA. In protein, gzip compress faster than bzip, while compression size is not as small as bzip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydna=np.random.choice(['A','T','C','G'],size = 1,replace=True,p=[0.25,0.25,0.25,0.25])\n",
    "dna_seq=\"\".join(mydna)\n",
    "open(\"nt_seq1\",\"w\").write(dna_seq)\n",
    "mydna=np.random.choice(['A','T','C','G'],size = 2,replace=True,p=[0.25,0.25,0.25,0.25])\n",
    "dna_seq=\"\".join(mydna)\n",
    "open(\"nt_seq2\",\"w\").write(dna_seq)\n",
    "mypro=np.random.choice(['A','G','I','L','P','V','F','W','Y','D','E','R','H','K','S','T','C','M','N','Q'],\\\n",
    "                       size = 1,replace=True,p=[0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05])\n",
    "pro_seq=\"\".join(mypro)\n",
    "open(\"pro_seq1\",\"w\").write(pro_seq)\n",
    "mypro=np.random.choice(['A','G','I','L','P','V','F','W','Y','D','E','R','H','K','S','T','C','M','N','Q'],\\\n",
    "                       size = 2,replace=True,p=[0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05])\n",
    "pro_seq=\"\".join(mypro)\n",
    "open(\"pro_seq2\",\"w\").write(pro_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gp120_homologs.fasta.txt gzip b'0.00user 0.00system 0:00.00elapsed 100%CPU (0avgtext+0avgdata 1676maxresident)k\\n0inputs+8outputs (0major+101minor)pagefaults 0swaps\\n'\n",
      "gp120_homologs.fasta.txt bzip2 b'0.00user 0.00system 0:00.00elapsed 100%CPU (0avgtext+0avgdata 1808maxresident)k\\n0inputs+8outputs (0major+164minor)pagefaults 0swaps\\n'\n",
      "gp120_homologs.fasta.txt.art ArithmeticCompress b'0.01user 0.00system 0:00.01elapsed 92%CPU (0avgtext+0avgdata 4268maxresident)k\\n0inputs+16outputs (0major+234minor)pagefaults 0swaps\\n'\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez,SeqIO,SeqFeature\n",
    "\n",
    "with open(\"gp120_homologs.fasta.txt\", 'w') as local_file:\n",
    "    Entrez.email = 'ruanzy@berkeley.edu'\n",
    "    handle = Entrez.esearch(db='nucleotide',\n",
    "                            retmax=10,\n",
    "                            term= 'HIV isolate',\n",
    "                            sort='relevance',\n",
    "                            idtype='acc')\n",
    "    for i in Entrez.read(handle)['IdList']:\n",
    "        handle = Entrez.efetch(db='nucleotide', id=i, rettype='fasta', retmode='text')\n",
    "        local_file.write(handle.read())\n",
    "        \n",
    "commands =[['time','gzip', '-k','gp120_homologs.fasta.txt'],\\\n",
    "           ['time','bzip2', '-k','gp120_homologs.fasta.txt'],\\\n",
    "           ['time','ArithmeticCompress', 'gp120_homologs.fasta.txt', 'gp120_homologs.fasta.txt.art']]\n",
    "for command in commands:\n",
    "    p = subprocess.Popen(command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    (stdoutdata, stderrdata)=p.communicate()\n",
    "    print(command[3],command[1],stderrdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compression ratio\n",
    "I would guess it would achieve better compression here than randomdata. Because random data has largest entropy, which is most difficult to compress. \n",
    "1. gzip: 0.235(real data); 0.292(random data)\n",
    "2. bzip: 0.240(real data); 0.273(random data)\n",
    "3. arithmetic: 0.494(real data); 0.25(random data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating compression of 1000 terabytes\n",
    "\n",
    "For binary microscope images, according to our benchmarking data, they are noncompressible at all when they are completely random. To be efficient enough, choose **_pbzip2_**\n",
    "\n",
    "For re-sequencing of genomes and plasmids, \n",
    "ArithmeticCompress with compress ratio of 0.25 and compress speed of 4.69MB/s will compress 0.39 TB a day, release 0.29TB space, and save 0.29*50=14.5\n",
    "Pbzip2 with compress ratio of 0.273 and compress speed of 100/0.66=151.52 MB/s will compress 12.48TB a day, release 9.08TB space from the original data, ans save 453.81\n",
    "Apparantly, use pbzip2 for genomes and plasmids.\n",
    "\n",
    "For protein sequnences, \n",
    "ArithmeticCompress with compress ratio of 0.54 and compress speed of 3.38 MB/s will compress 0.28 TB a day, release 0.13TB space, and save 6.4\n",
    "Pbzip2 with compress ratio of 0.553 and compress speed of 100/0.78=128.21 MB/s will compress 10.56TB a day, release 4.72TB space from the original data, ans save 236.10\n",
    "\n",
    "In conclusion, use pbzip2 to compress re-sequencing of genomes and plasmid everyday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
